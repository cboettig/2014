---
layout: post
category: ecology
published: false
---




I agree with Brian that what you describe as theory vs modeling really
sounds more like May's strategic vs tactical models, or as you already
cited, Levin's "The Strategy of Model Building in Population Biology". I
think a lot of tensions we see today were already well reflected when
he was writing in 1966, with similar cultural differences that reflected
the strength of the different models.

You focus on a trend from strategic to more tactical modeling, but also on
a trend towards model fitting to data. I wonder to what extent this is a
shift from 'mathematical modeling' towards 'statistical modeling', where
we are concerned more with quantitative than qualitative comparisons;
or even just a shift towards greater integration between theoretical
and empirical work.  You don't seem to develop here the relative roles
of data in the different approaches you consider here.

To me, "pure theory" is the realm of mathematical proofs, showing what
are the logical consequences of certain assumptions.  I'm rather surprised
that you highlight Chesson's work or the Price equation as a kind of grey
area -- I think they are clearly examples of (this kind of) theory. How
general such theorems are is largely a question of empiricism, e.g. how
often are the assumptions met -- I've never understood why generality
should be a postulate in order to do theory, as your construction makes
it out, rather than an empirical question to test after the fact. (Of
course pure theory can play a role in that generalization too -- such
as relaxing assumptions about white noise in demonstrating coexistence
or existence of bet-hedging strategies).

To me, this kind of theory includes both the analytically tractable
equations we can manipulate in chalk (e.g. Levins), but also the really
complex, rich individual-based simulations such as we see from Ian
Couzin's work.  Both also make assumptions (as Tony Ives emphasizes,
it is usually the assumptions that we are really testing -- testing a
model's predictions is just a means to that end) that we can confront
with empirical study.

To me, this interaction of doing good theoretical work that is independent
of data (regardless of whether it is expressed in the language of math,
numerical simulations, or pictures and stories), and then figuring out
how to empirically test these assumptions is more interesting than the
kind of straw-man dichotomy between whether we need "general laws" and or
"a different black box predictive algorithm for every system".
