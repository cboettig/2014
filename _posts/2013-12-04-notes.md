---
layout: post
published: false

---


today

- rfishbase added feature (Metabolism data) in response to request. Details in [Issue #14](https://github.com/ropensci/rfishbase/issues/14)
- Logisitics / paperwork catch up


primary to-dos:


Speaker request

- [ICIS meeting](http://icis.ucdavis.edu/?page_id=22) 

<!--
Literature doesn't scale.  Engagement with most content is superficial.  You can utilize only a decreasing amount of content for each paper you add.  Software-based contributions scale.  You don't just get the concept of a better algorithm you never have time to implement or understand fully.  you get the algorithm.  This sounds superficial - you can use it with no understanding.  Yet we use papers like this all the time, when we cite papers for having showed what they claim.  Having to understand and rewrite the algorithm yourself is like saying: don't cite anything until you have reproduced the results in your own lab.  With a key difference.  Others can critique and improve .

What about non-computational procedures?  I don't know - that stuff is hard. The same concepts still apply - use of standards, documentation, etc all help.  Design for replicability, because it lets these approaches scale. But let's solve the easier problem of computational replicability first.  

People worry that 'big data' means superficial understanding of the data.  I think the opposite.  As literature grows, engagement with the details of the data details is increasingly superficial.  

People worry that data publishing is a coup for data consumers (theorists), since they will get more publications.  I think it is a coup for data producers, if the data truly is so excellent that anyone can easily turn out lots of papers, it is quite clear that the data is worth more than the papers.  

The future is here. rOpenSci: eml publish data, access data, use data. engage with researchers.  Engage with software.  

Data, code are things we can interact with at scale
Publishing that scales.

-->
