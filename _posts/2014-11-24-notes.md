---
layout: post
category: computing
published: false
tags: 
- infrastructure
- docker
- coreos
- digitalocean
---


## A secure docker registry ##


### First pass: nginx on ubuntu server ###



- After a few false starts, decided the [digitalocean guide](https://www.digitalocean.com/community/tutorials/how-to-set-up-a-private-docker-registry-on-ubuntu-14-04) is easily the best (though steps 1-3 can be skipped by using a containerized `registry` instead).  


- Note: At first, nginx refuses to run because there's was `default` configuration in `cd /etc/nginx/sites-enabled` that tries to create a conflict.  Remove this and things go pretty nicely.  

- Note: Running the registry container explicitly on port `127.0.0.1` provides an internal-only port that we can then point to from nginx. (Actually this will no longer matter when we use a containerized `nginx`, since we will simply not export these ports at all, but only expose the port of the `nginx` load balancer.  

- Running and configuring `nginx` Note that keys are specific to the url. I create a root key and certificate (`crt`), a server key, server signing request (`csr`), and then sign the latter with the former to get the server certificate. 

```bash
openssl genrsa -out dockerCA.key 2048
openssl req -x509 -new -nodes -key dockerCA.key -days 10000 -out dockerCA.crt -subj '/C=US/ST=Oregon/L=Portland/CN=coreos.carlboettiger.info'
openssl genrsa -out docker-registry.key 2048
openssl req -new -key docker-registry.key -out docker-registry.csr -subj '/C=US/ST=Oregon/L=Portland/CN=coreos.carlboettiger.info'
openssl x509 -req -in docker-registry.csr -CA dockerCA.crt -CAkey dockerCA.key -CAcreateserial -out docker-registry.crt -days 10000
```


- Cannot get nginx to run as a container. Not sure why.  Thinks having `daemon off;` at the top of `/etc/nginx/nginx.conf` is a duplicate, desipte being recommended.  Removing that, thinks `upstream` directive is not allowed here. Not sure what to make of these errors, ended up running an ubuntu container and then just installing `nginx` etc following the digitalocean guide. 

- We get a 502 error when calling `curl` against the the `nginx` container-provided URL (with or without SSL enabled), since from inside the `nginx` container we cannot access the host addresses.  The simplest solution is to add `--net="host"` when we `docker run` the `nginx` container, but this isn't particularly secure.  Instead, we'll link directly to the ports of the `registry` container like this:

```bash
docker run  --name=registry -p 8080:8080 registry
docker run --name=nginx --net=container:registry nginx
```

Note that we do not need to export the registry port (e.g. `-p 5000:5000`) at all, but we do need to export the `nginx` load-balancer port _from the `registry` container_ first, since we will simply be linking it's network with the special `--net=container:registry`.  


## Migrating gitlab between servers ##

Note that there is no need to migrate the redis and postgresql containers manually.  Migrating the backup file over to the corresponding location in the linked volume and then running the backup-restore is sufficient.  Upgrading is also surprisingly smooth; we can backup (just in case), then stop and remove the container (leaving the `redis` and `postgresql` containers running), pull and relaunch with otherwise matched option arguments and the upgrade runs automatically.

When first launching the `gitlab` container on a tiny droplet running coreos, my droplet seems invariably to hang.  Rebooting from the digitalocean terminal seems to fix this. A nice feature of `fleet` is that all the containers are restarted automatically after reboot, unlike when running these directly from `docker` on my ubuntu machine.

## Notes on fleet unit files ## 

Fleet unit files are actually pretty handy and straight forward.  One trick is that we must quote commands in which we want to make use of environmental variables. For instance, one must write:

```
Environment="VERSION=1.0"
ExecStart=/bin/bash -c "/usr/bin/docker run image:${VERSION}"
```

in a `Service` block, rather than `ExecStart=/usr/bin/docker run ...` directly, for the substitution to work. It seems if we are using the more standard practice of environment files (which after all is the necessary approach to avoid having to edit the unit file directly one way or another anyway), we can avoid the `bin/bash` wrapper and insert the environment reference directly.

If we're not doing anything fancy wrt load balancing between different servers, we don't have that much use for the corresponding "sidekick" unit files that keep our global `etcd` registry up to date. Perhaps these will see more use later.  


## Cloud-config ##

Note that we need to refresh the discovery url prettymuch anytime we completely destroy the cluster.

A few edits to my cloud-config to handle initiating swap, essential for running most things (gitlab, rstudio) on tiny droplets. Still requires one manual reboot for the allocation to take effect.   
